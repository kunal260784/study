{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9de05f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\RAG\\learningRAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest\n",
    "from typing import Callable, Literal\n",
    "from langchain.messages import SystemMessage\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a20f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cd561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    model_provider=\"openai\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "complexllm = init_chat_model(\n",
    "    model=\"gpt-4o\",\n",
    "    model_provider=\"openai\",\n",
    "    temperature=1.2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec2cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judgement(BaseModel):\n",
    "    \"\"\"  \n",
    "    Class is created to get judgement in structured way on user query from LLM \n",
    "    \"\"\"\n",
    "\n",
    "    decision: Literal[\"SIMPLE\",\"COMPLEX\"] = Field(description=\"Field will have value either Simple or Complex.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694cf0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_model_call\n",
    "def modelcall(request: ModelRequest, handler: Callable) -> Callable:\n",
    "    \"\"\"  \n",
    "        function is a judge that analyze the request and find if request is simple or complex.\n",
    "        If Request is simple it use small and cheap model to handle the request.\n",
    "        If request is complex it will use expensive model to handle the request.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    msg = request.messages[-1].content\n",
    "\n",
    "    prompt = f\"\"\" \n",
    "                You are a Smart Judge which analyze the query received from User. Decide if Query is Simple of Complex.\n",
    "                If you found Query is simple Query return SIMPLE\n",
    "                If you found Query is Complex Return COMPLEX\n",
    "\n",
    "                Query: {msg}\n",
    "\n",
    "                Example:\n",
    "                What is Power BI?\n",
    "                Output: SIMPLE\n",
    "            \"\"\"\n",
    "    \n",
    "    judge = llm.with_structured_output(Judgement)\n",
    "    judgement = judge.invoke([SystemMessage(content=prompt)])\n",
    "    print(judgement.decision)\n",
    "\n",
    "\n",
    "\n",
    "    if judgement.decision == \"COMPLEX\":\n",
    "        request.override(model=complexllm)\n",
    "    else:\n",
    "        request.override(model=llm)\n",
    "    \n",
    "    return handler(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3063777",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactAgent = create_agent(\n",
    "    model= llm,\n",
    "    middleware=[modelcall]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a03e8188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMPLE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 284,\n",
       "  'prompt_tokens': 13,\n",
       "  'total_tokens': 297,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_provider': 'openai',\n",
       " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
       " 'system_fingerprint': 'fp_c4585b5b9c',\n",
       " 'id': 'chatcmpl-CoxaIAFxNo0b1gt3ZZxe5WLxMh3Db',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = reactAgent.invoke({\"messages\" : \"What is LLM ? \"})\n",
    "result['messages'][-1].response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4687af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is LLM ? \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LLM stands for \"Large Language Model.\" It refers to a type of artificial intelligence model that is designed to understand and generate human language. These models are typically trained on vast amounts of text data and use deep learning techniques, particularly neural networks, to learn patterns, grammar, facts, and even some reasoning abilities from the data.\n",
      "\n",
      "Key characteristics of LLMs include:\n",
      "\n",
      "1. **Scale**: They are called \"large\" because they often have billions or even trillions of parameters, which are the weights and biases that the model learns during training.\n",
      "\n",
      "2. **Versatility**: LLMs can perform a wide range of language-related tasks, such as text generation, translation, summarization, question answering, and more.\n",
      "\n",
      "3. **Contextual Understanding**: They can generate coherent and contextually relevant text based on the input they receive, making them useful for applications like chatbots, content creation, and more.\n",
      "\n",
      "4. **Pre-training and Fine-tuning**: LLMs are usually pre-trained on a diverse dataset and can be fine-tuned on specific tasks or domains to improve their performance in those areas.\n",
      "\n",
      "Examples of LLMs include OpenAI's GPT (Generative Pre-trained Transformer) series, Google's BERT (Bidirectional Encoder Representations from Transformers), and others. These models have significantly advanced the field of natural language processing (NLP) and have numerous applications across various industries.\n"
     ]
    }
   ],
   "source": [
    "for item in result['messages']:\n",
    "    item.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
